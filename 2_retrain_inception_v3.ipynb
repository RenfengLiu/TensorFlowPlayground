{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0-rc0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sys import path as import_path\n",
    "import_path.append('/home/robin/code/models/research/slim/')\n",
    "from nets import inception\n",
    "# from datasets import dataset_utils\n",
    "# from tensorflow.contrib.layers.python.layers import layers as layers_lib\n",
    "slim = tf.contrib.slim\n",
    "image_size = inception.inception_v3.default_image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "import numpy as np\n",
    "\n",
    "def gen_dataset(filenames):\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    input_mean = 128\n",
    "    input_std = 128\n",
    "    def parser(record):\n",
    "        keys_to_features = {\n",
    "          'height': tf.FixedLenFeature((), tf.int64),\n",
    "          'width': tf.FixedLenFeature((), tf.int64),\n",
    "          'image_raw': tf.FixedLenFeature((), tf.string),\n",
    "          'lable': tf.FixedLenFeature((), tf.int64)\n",
    "        }\n",
    "        parsed = tf.parse_single_example(record, keys_to_features)\n",
    "        image = parsed[\"image_raw\"]\n",
    "        image = tf.decode_raw(image, tf.uint8)\n",
    "        image = tf.reshape(image, [299, 299, 3])\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = tf.subtract(image, input_mean)\n",
    "        image = tf.multiply(image, 1.0/input_std)\n",
    "        label = tf.cast(parsed[\"lable\"], tf.int32)\n",
    "        return image, label\n",
    "    \n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.shuffle(buffer_size=3000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def load_pretrained_net():\n",
    "#     checkpoint_exclude_scopes=[\"InceptionV3/Logits\", \"InceptionV3/AuxLogits\"]\n",
    "#     exclusions = [scope.strip() for scope in checkpoint_exclude_scopes]\n",
    "\n",
    "#     variables_to_restore = []\n",
    "#     for var in slim.get_model_variables():\n",
    "#         excluded = False\n",
    "#         for exclusion in exclusions:\n",
    "#             if var.op.name.startswith(exclusion):\n",
    "#                 excluded = True\n",
    "#                 break\n",
    "#         if not excluded:\n",
    "#             variables_to_restore.append(var)\n",
    "#     return slim.assign_from_checkpoint_fn(model_path, variables_to_restore)\n",
    "\n",
    "def get_variables_to_restore():\n",
    "    checkpoint_exclude_scopes=[\"InceptionV3/Logits\", \"InceptionV3/AuxLogits\"]\n",
    "    exclusions = [scope.strip() for scope in checkpoint_exclude_scopes]\n",
    "\n",
    "    variables_to_restore = []\n",
    "    for var in slim.get_model_variables():\n",
    "        excluded = False\n",
    "        for exclusion in exclusions:\n",
    "            if var.op.name.startswith(exclusion):\n",
    "                excluded = True\n",
    "                break\n",
    "        if not excluded:\n",
    "            variables_to_restore.append(var)\n",
    "    return variables_to_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_output(images, num_classes, dropout_keep_prob=1.0, is_training=True, reuse=False):\n",
    "    with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "        logits, endpoints = inception.inception_v3(\n",
    "            images,\n",
    "            dropout_keep_prob=dropout_keep_prob,\n",
    "            num_classes=num_classes,\n",
    "            is_training=is_training,\n",
    "            reuse=reuse\n",
    "        )\n",
    "    net = endpoints['Mixed_7c'] # take the layer just before logits\n",
    "    net = tf.stop_gradient(net) # we keep inception model fixed\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path = '/home/robin/tmp/train_logs'\n",
    "model_path = '/home/robin/project/inception_v3.ckpt'\n",
    "\n",
    "num_classes = 5\n",
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "\n",
    "_data = tf.placeholder(tf.float32, [None, image_size, image_size, 3])\n",
    "_labels = tf.placeholder(tf.int32, [None])\n",
    "_keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logits_train = get_fc_output(_data, num_classes, dropout_keep_prob=_keep_prob, is_training=True, reuse=False)\n",
    "# logits_test = get_fc_output(_data, num_classes, dropout_keep_prob=_keep_prob, is_training=False, reuse=True)\n",
    "\n",
    "logits = get_fc_output(_data, num_classes, _keep_prob)\n",
    "logits_train = logits\n",
    "logits_test = logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loss\n",
    "one_hot_labels = slim.one_hot_encoding(_labels, num_classes)\n",
    "total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits_train, labels=one_hot_labels))\n",
    "# total_loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits_train, labels=one_hot_labels)\n",
    "\n",
    "tf.summary.scalar('losses/Total_Loss', total_loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(total_loss)  \n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## validation \n",
    "score = tf.nn.softmax(logits_test)\n",
    "correct_pred = tf.equal(tf.argmax(score, 1), tf.argmax(one_hot_labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## dataset \n",
    "with tf.name_scope('train_data'):\n",
    "    train_dataset   = gen_dataset(['./retrain_flowers/flower_train.tfrecords'])\n",
    "    train_iterator  = train_dataset.make_initializable_iterator()\n",
    "    next_train_batch  = train_iterator.get_next()\n",
    "\n",
    "with tf.name_scope('val_data'):\n",
    "    val_dataset     = gen_dataset(['./retrain_flowers/flower_test.tfrecords'])\n",
    "    val_iterator    = val_dataset.make_initializable_iterator()\n",
    "    next_val_batch  = val_iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## accuracy\n",
    "def get_test_acc(sess, test_op):\n",
    "    sess.run(val_iterator.initializer)\n",
    "    total = 0.0\n",
    "    i = 0\n",
    "    total_num = 0\n",
    "    while True:\n",
    "        try:\n",
    "            images, labels = sess.run(next_val_batch)\n",
    "            acc = sess.run(test_op, feed_dict={_data:images, _labels:labels, _keep_prob:1.0})\n",
    "            total += acc * images.shape[0]\n",
    "            total_num += images.shape[0]\n",
    "            i += 1\n",
    "        except Exception:\n",
    "            break\n",
    "    acc_ = total/total_num  \n",
    "    return acc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model_path = \"/home/robin/tmp/fine_tuned_model.ckpt\"\n",
    "model_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/robin/project/inception_v3.ckpt\n",
      "before fine tune: acc 0.210597824791\n",
      "epic 1, time used: 40, run valiation acc: 0.245924\n",
      "epic 2, time used: 36, run valiation acc: 0.251359\n",
      "epic 3, time used: 36, run valiation acc: 0.256793\n",
      "epic 4, time used: 36, run valiation acc: 0.251359\n",
      "epic 5, time used: 36, run valiation acc: 0.267663\n",
      "epic 6, time used: 36, run valiation acc: 0.262228\n",
      "epic 7, time used: 36, run valiation acc: 0.298913\n",
      "epic 8, time used: 36, run valiation acc: 0.324728\n",
      "epic 9, time used: 36, run valiation acc: 0.375000\n",
      "epic 10, time used: 36, run valiation acc: 0.387228\n",
      "epic 11, time used: 36, run valiation acc: 0.403533\n",
      "epic 12, time used: 36, run valiation acc: 0.442935\n",
      "epic 13, time used: 36, run valiation acc: 0.415761\n",
      "epic 14, time used: 36, run valiation acc: 0.563859\n",
      "epic 15, time used: 36, run valiation acc: 0.589674\n",
      "epic 16, time used: 36, run valiation acc: 0.611413\n",
      "epic 17, time used: 36, run valiation acc: 0.610054\n",
      "Step:  500\n",
      "epic 18, time used: 36, run valiation acc: 0.633152\n",
      "epic 19, time used: 36, run valiation acc: 0.635870\n",
      "epic 20, time used: 36, run valiation acc: 0.699728\n",
      "epic 21, time used: 36, run valiation acc: 0.679348\n",
      "epic 22, time used: 36, run valiation acc: 0.682065\n",
      "epic 23, time used: 36, run valiation acc: 0.694293\n",
      "epic 24, time used: 36, run valiation acc: 0.660326\n",
      "epic 25, time used: 36, run valiation acc: 0.695652\n",
      "epic 26, time used: 36, run valiation acc: 0.692935\n",
      "epic 27, time used: 36, run valiation acc: 0.710598\n",
      "epic 28, time used: 36, run valiation acc: 0.697011\n",
      "epic 29, time used: 36, run valiation acc: 0.713315\n",
      "epic 30, time used: 36, run valiation acc: 0.737772\n",
      "epic 31, time used: 36, run valiation acc: 0.737772\n",
      "epic 32, time used: 36, run valiation acc: 0.697011\n",
      "epic 33, time used: 36, run valiation acc: 0.725543\n",
      "epic 34, time used: 36, run valiation acc: 0.725543\n",
      "Step:  1000\n",
      "epic 35, time used: 36, run valiation acc: 0.733696\n",
      "epic 36, time used: 36, run valiation acc: 0.737772\n",
      "epic 37, time used: 36, run valiation acc: 0.737772\n",
      "epic 38, time used: 36, run valiation acc: 0.766304\n",
      "epic 39, time used: 36, run valiation acc: 0.756793\n",
      "epic 40, time used: 36, run valiation acc: 0.760870\n",
      "epic 41, time used: 36, run valiation acc: 0.758152\n",
      "epic 42, time used: 36, run valiation acc: 0.774457\n",
      "epic 43, time used: 36, run valiation acc: 0.760870\n",
      "epic 44, time used: 36, run valiation acc: 0.788043\n",
      "epic 45, time used: 36, run valiation acc: 0.752717\n",
      "epic 46, time used: 36, run valiation acc: 0.764946\n",
      "epic 47, time used: 36, run valiation acc: 0.793478\n",
      "epic 48, time used: 36, run valiation acc: 0.790761\n",
      "epic 49, time used: 36, run valiation acc: 0.760870\n",
      "epic 50, time used: 36, run valiation acc: 0.766304\n",
      "epic 51, time used: 36, run valiation acc: 0.781250\n",
      "Step:  1500\n",
      "epic 52, time used: 36, run valiation acc: 0.771739\n",
      "epic 53, time used: 36, run valiation acc: 0.770380\n",
      "epic 54, time used: 36, run valiation acc: 0.764946\n",
      "epic 55, time used: 36, run valiation acc: 0.792120\n",
      "epic 56, time used: 36, run valiation acc: 0.801630\n",
      "epic 57, time used: 36, run valiation acc: 0.783967\n",
      "epic 58, time used: 36, run valiation acc: 0.813859\n",
      "epic 59, time used: 36, run valiation acc: 0.763587\n",
      "epic 60, time used: 36, run valiation acc: 0.827446\n",
      "epic 61, time used: 36, run valiation acc: 0.802989\n",
      "epic 62, time used: 36, run valiation acc: 0.801630\n",
      "epic 63, time used: 36, run valiation acc: 0.796196\n",
      "epic 64, time used: 36, run valiation acc: 0.809783\n",
      "epic 65, time used: 36, run valiation acc: 0.808424\n",
      "epic 66, time used: 36, run valiation acc: 0.813859\n",
      "epic 67, time used: 36, run valiation acc: 0.788043\n",
      "epic 68, time used: 36, run valiation acc: 0.800272\n",
      "Step:  2000\n",
      "epic 69, time used: 36, run valiation acc: 0.823370\n",
      "epic 70, time used: 36, run valiation acc: 0.801630\n",
      "epic 71, time used: 36, run valiation acc: 0.797554\n",
      "epic 72, time used: 36, run valiation acc: 0.781250\n",
      "epic 73, time used: 36, run valiation acc: 0.782609\n",
      "epic 74, time used: 36, run valiation acc: 0.802989\n",
      "epic 75, time used: 36, run valiation acc: 0.816576\n",
      "epic 76, time used: 36, run valiation acc: 0.804348\n",
      "epic 77, time used: 36, run valiation acc: 0.777174\n",
      "epic 78, time used: 36, run valiation acc: 0.813859\n",
      "epic 79, time used: 36, run valiation acc: 0.807065\n",
      "epic 80, time used: 36, run valiation acc: 0.808424\n",
      "epic 81, time used: 36, run valiation acc: 0.788043\n",
      "epic 82, time used: 36, run valiation acc: 0.801630\n",
      "epic 83, time used: 36, run valiation acc: 0.807065\n",
      "epic 84, time used: 36, run valiation acc: 0.783967\n",
      "epic 85, time used: 36, run valiation acc: 0.786685\n",
      "epic 86, time used: 36, run valiation acc: 0.802989\n",
      "Step:  2500\n",
      "epic 87, time used: 36, run valiation acc: 0.797554\n",
      "epic 88, time used: 36, run valiation acc: 0.807065\n",
      "epic 89, time used: 36, run valiation acc: 0.790761\n",
      "epic 90, time used: 36, run valiation acc: 0.778533\n",
      "epic 91, time used: 36, run valiation acc: 0.790761\n",
      "epic 92, time used: 36, run valiation acc: 0.793478\n",
      "epic 93, time used: 36, run valiation acc: 0.804348\n",
      "epic 94, time used: 36, run valiation acc: 0.808424\n",
      "epic 95, time used: 36, run valiation acc: 0.800272\n",
      "epic 96, time used: 36, run valiation acc: 0.792120\n",
      "epic 97, time used: 36, run valiation acc: 0.807065\n",
      "epic 98, time used: 36, run valiation acc: 0.798913\n",
      "epic 99, time used: 36, run valiation acc: 0.808424\n",
      "epic 100, time used: 36, run valiation acc: 0.804348\n",
      "after fine tune: acc 0.797554341671\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# session = tf.Session(config=config)\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "    variables_to_restore = get_variables_to_restore()\n",
    "    restorer = tf.train.Saver(variables_to_restore) \n",
    "    restorer.restore(sess, model_path)\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    acc = get_test_acc(sess, accuracy)\n",
    "    print('before fine tune: acc', acc)  \n",
    "\n",
    "    sess.run(train_iterator.initializer)\n",
    "    num_epoc = 0\n",
    "    i = 0\n",
    "    start = time.time()\n",
    "    while num_epoc < 100:\n",
    "        try:\n",
    "            images, labels = sess.run(next_train_batch)\n",
    "            _, summary = sess.run([train_op, merged_summary_op], feed_dict={_data:images, \n",
    "                                                                            _labels:labels, \n",
    "                                                                            _keep_prob:0.9})\n",
    "            summary_writer.add_summary(summary, i)\n",
    "            i += 1\n",
    "            if i%500 == 0:\n",
    "                print('Step: ', i)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            acc = get_test_acc(sess, accuracy)\n",
    "            num_epoc += 1\n",
    "            print('epic %d, time used: %d, run valiation acc: %f'%(num_epoc, time.time() - start, acc))   \n",
    "            start = time.time()\n",
    "\n",
    "            sess.run(train_iterator.initializer)\n",
    "            images, labels = sess.run(next_train_batch)\n",
    "            sess.run([train_op, merged_summary_op], feed_dict={_data:images, \n",
    "                                                               _labels:labels, \n",
    "                                                               _keep_prob:0.9})\n",
    "\n",
    "    acc = get_test_acc(sess, accuracy)\n",
    "    print('after fine tune: acc', acc) \n",
    "    save_path = model_saver.save(sess, final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/robin/tmp/fine_tuned_model.ckpt\n",
      "after fine tune: acc 0.796195645695\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    # Initialize variables\n",
    "    sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "\n",
    "    # Restore model weights from previously saved model\n",
    "    load_path = model_saver.restore(sess, final_model_path)\n",
    "    acc = get_test_acc(sess, accuracy)\n",
    "    print('after fine tune: acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
