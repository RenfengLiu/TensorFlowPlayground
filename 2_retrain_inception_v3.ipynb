{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0-rc0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sys import path as import_path\n",
    "import_path.append('/home/robin/code/models/research/slim/')\n",
    "from nets import inception\n",
    "# from datasets import dataset_utils\n",
    "# from tensorflow.contrib.layers.python.layers import layers as layers_lib\n",
    "slim = tf.contrib.slim\n",
    "image_size = inception.inception_v3.default_image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 76\n",
    "import numpy as np\n",
    "\n",
    "def gen_dataset(filenames):\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    input_mean = 128\n",
    "    input_std = 128\n",
    "    def parser(record):\n",
    "        keys_to_features = {\n",
    "          'height': tf.FixedLenFeature((), tf.int64),\n",
    "          'width': tf.FixedLenFeature((), tf.int64),\n",
    "          'image_raw': tf.FixedLenFeature((), tf.string),\n",
    "          'lable': tf.FixedLenFeature((), tf.int64)\n",
    "        }\n",
    "        parsed = tf.parse_single_example(record, keys_to_features)\n",
    "        image = parsed[\"image_raw\"]\n",
    "        image = tf.decode_raw(image, tf.uint8)\n",
    "        image = tf.reshape(image, [299, 299, 3])\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = tf.subtract(image, input_mean)\n",
    "        image = tf.multiply(image, 1.0/input_std)\n",
    "        label = tf.cast(parsed[\"lable\"], tf.int32)\n",
    "        return image, label\n",
    "    \n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.shuffle(buffer_size=3000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def load_pretrained_net():\n",
    "#     checkpoint_exclude_scopes=[\"InceptionV3/Logits\", \"InceptionV3/AuxLogits\"]\n",
    "#     exclusions = [scope.strip() for scope in checkpoint_exclude_scopes]\n",
    "\n",
    "#     variables_to_restore = []\n",
    "#     for var in slim.get_model_variables():\n",
    "#         excluded = False\n",
    "#         for exclusion in exclusions:\n",
    "#             if var.op.name.startswith(exclusion):\n",
    "#                 excluded = True\n",
    "#                 break\n",
    "#         if not excluded:\n",
    "#             variables_to_restore.append(var)\n",
    "#     return slim.assign_from_checkpoint_fn(model_path, variables_to_restore)\n",
    "\n",
    "def get_variables_to_restore():\n",
    "    checkpoint_exclude_scopes=[\"InceptionV3/Logits\", \"InceptionV3/AuxLogits\"]\n",
    "    exclusions = [scope.strip() for scope in checkpoint_exclude_scopes]\n",
    "\n",
    "    variables_to_restore = []\n",
    "    for var in slim.get_model_variables():\n",
    "        excluded = False\n",
    "        for exclusion in exclusions:\n",
    "            if var.op.name.startswith(exclusion):\n",
    "                excluded = True\n",
    "                break\n",
    "        if not excluded:\n",
    "            variables_to_restore.append(var)\n",
    "    return variables_to_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_output(images, num_classes, dropout_keep_prob=1.0, is_training=True, reuse=False):\n",
    "    with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "        logits, endpoints = inception.inception_v3(\n",
    "            images,\n",
    "            dropout_keep_prob=dropout_keep_prob,\n",
    "            num_classes=num_classes,\n",
    "            is_training=is_training,\n",
    "            reuse=reuse\n",
    "        )\n",
    "    net = endpoints['Mixed_7c'] # take the layer just before logits\n",
    "    net = tf.stop_gradient(net) # we keep inception model fixed\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_path = '/home/robin/tmp/train_logs'\n",
    "model_path = '/home/robin/project/inception_v3.ckpt'\n",
    "\n",
    "num_classes = 5\n",
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "\n",
    "_data = tf.placeholder(tf.float32, [None, image_size, image_size, 3])\n",
    "_labels = tf.placeholder(tf.int32, [None])\n",
    "_keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logits_train = get_fc_output(_data, num_classes, dropout_keep_prob=0.8, is_training=True, reuse=False)\n",
    "# logits_test = get_fc_output(_data, num_classes, dropout_keep_prob=1.0, is_training=False, reuse=True)\n",
    "\n",
    "logits = get_fc_output(_data, num_classes, _keep_prob)\n",
    "logits_train = logits\n",
    "logits_test = logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loss\n",
    "one_hot_labels = slim.one_hot_encoding(_labels, num_classes)\n",
    "total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits_train, labels=one_hot_labels))\n",
    "tf.summary.scalar('losses/Total_Loss', total_loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(total_loss)  \n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## validation \n",
    "score = tf.nn.softmax(logits_test)\n",
    "correct_pred = tf.equal(tf.argmax(score, 1), tf.argmax(one_hot_labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## dataset \n",
    "with tf.name_scope('train_data'):\n",
    "    train_dataset   = gen_dataset(['./retrain_flowers/flower_train.tfrecords'])\n",
    "    train_iterator  = train_dataset.make_initializable_iterator()\n",
    "    next_train_batch  = train_iterator.get_next()\n",
    "\n",
    "with tf.name_scope('val_data'):\n",
    "    val_dataset     = gen_dataset(['./retrain_flowers/flower_test.tfrecords'])\n",
    "    val_iterator    = val_dataset.make_initializable_iterator()\n",
    "    next_val_batch  = val_iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## accuracy\n",
    "def get_test_acc(sess, test_op):\n",
    "    sess.run(val_iterator.initializer)\n",
    "    total = 0.0\n",
    "    i = 0\n",
    "    total_num = 0\n",
    "    while True:\n",
    "        try:\n",
    "            images, labels = sess.run(next_val_batch)\n",
    "            acc = sess.run(test_op, feed_dict={_data:images, _labels:labels, _keep_prob:1.0})\n",
    "            total += acc * images.shape[0]\n",
    "            total_num += images.shape[0]\n",
    "            i += 1\n",
    "        except Exception:\n",
    "            break\n",
    "    acc_ = total/total_num  \n",
    "    return acc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model_path = \"/home/robin/tmp/fine_tuned_model.ckpt\"\n",
    "model_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/robin/project/inception_v3.ckpt\n",
      "before fine tune: acc 0.190217391831\n",
      "epic 1, time used: 55, run valiation acc: 0.243207\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "    variables_to_restore = get_variables_to_restore()\n",
    "    restorer = tf.train.Saver(variables_to_restore) \n",
    "    restorer.restore(sess, model_path)\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    acc = get_test_acc(sess, accuracy)\n",
    "    print('before fine tune: acc', acc)  \n",
    "\n",
    "    sess.run(train_iterator.initializer)\n",
    "    num_epoc = 0\n",
    "    i = 0\n",
    "    start = time.time()\n",
    "    while num_epoc < 100:\n",
    "        try:\n",
    "            images, labels = sess.run(next_train_batch)\n",
    "            _, summary = sess.run([train_op, merged_summary_op], feed_dict={_data:images, _labels:labels, _keep_prob:0.9})\n",
    "            summary_writer.add_summary(summary, i)\n",
    "            i += 1\n",
    "            if i%500 == 0:\n",
    "                print('Step: ', i)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            acc = get_test_acc(sess, accuracy)\n",
    "            num_epoc += 1\n",
    "            print('epic %d, time used: %d, run valiation acc: %f'%(num_epoc, time.time() - start, acc))   \n",
    "            start = time.time()\n",
    "\n",
    "            sess.run(train_iterator.initializer)\n",
    "            images, labels = sess.run(next_train_batch)\n",
    "            sess.run([train_op, merged_summary_op], feed_dict={_data:images, _labels:labels, _keep_prob:0.9})\n",
    "\n",
    "    acc = get_test_acc(sess, accuracy)\n",
    "    print('after fine tune: acc', acc) \n",
    "    save_path = model_saver.save(sess, final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "\n",
    "    # Restore model weights from previously saved model\n",
    "    load_path = model_saver.restore(sess, final_model_path)\n",
    "    acc = get_test_acc(sess, accuracy)\n",
    "    print('after fine tune: acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
